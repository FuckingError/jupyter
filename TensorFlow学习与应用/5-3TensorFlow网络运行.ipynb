{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用tf.summary.scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加上tf.reset_default_graph() 就不会报错了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#1.下载mnist数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True) #让label转换成one-hot格式\n",
    "\n",
    "#2对数据进行操作\n",
    "#2.1分成多个batch\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size  #//整除\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)#平均值\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "    tf.summary.scalar('stddev',stddev)#标准差\n",
    "    tf.summary.scalar('max',tf.reduce_max(var))\n",
    "    tf.summary.scalar('min',tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram',var)\n",
    "\n",
    "#2.2为data 和 label 创建plcaeholder   #！None 具体多少数量之后指定\n",
    "#命名空间\n",
    "with tf.name_scope(name='input'):\n",
    "    data = tf.placeholder(tf.float32,[None,784],name='data')\n",
    "    label = tf.placeholder(tf.float32,[None,10],name='label')\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "learn = tf.Variable(0.001,dtype=tf.float32)\n",
    "#3.创建神经网络\n",
    "#3.1权重参数 和 偏置项\n",
    "\n",
    "#输出层\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weight'):\n",
    "        W = tf.Variable(tf.truncated_normal([784,10],stddev=0.1),name='W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([10])+0.1,name='b')\n",
    "        variable_summaries(b)\n",
    "    #3.2softmax 为分类求出概率\n",
    "    with tf.name_scope('mul_add'):\n",
    "        mul_add = tf.matmul(data,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(mul_add) \n",
    "\n",
    "#3.3使用二次代价函数计算loss值\n",
    "# loss = tf.reduce_mean(tf.square(prediction-label))\n",
    "#使用交叉熵 计算loss\\\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=label,logits=prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "#3.4使用梯度下降法\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learn).minimize(loss)\n",
    "\n",
    "#4.求出准确率\n",
    "#4.1 得出一个判断正确与否的 布尔类型list\n",
    "#! arg_max（） 返回一维张量中最大的索引值 1表示按行比较   这里 前一个就是取出one-hot的那个1所在的位置 后一个就是取出概率值最大的位置\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(label,1),tf.argmax(prediction,1))\n",
    "#4.2 计算正确率   将布尔型列表转换成 0 1 求出平均值就是正确率\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = (tf.reduce_mean(tf.cast(correct_prediction,tf.float32)))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并所有的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train: 0.88714546 test: 0.8964\n",
      "1 train: 0.9043273 test: 0.9107\n",
      "2 train: 0.91185457 test: 0.9154\n",
      "3 train: 0.9157636 test: 0.9179\n",
      "4 train: 0.9186 test: 0.92\n",
      "5 train: 0.9193636 test: 0.9225\n",
      "6 train: 0.92056364 test: 0.9225\n",
      "7 train: 0.92178184 test: 0.9221\n",
      "8 train: 0.9219273 test: 0.923\n",
      "9 train: 0.92225456 test: 0.9229\n",
      "10 train: 0.92227274 test: 0.9228\n",
      "11 train: 0.9223273 test: 0.9229\n",
      "12 train: 0.9224 test: 0.9231\n",
      "13 train: 0.92243636 test: 0.9231\n",
      "14 train: 0.9224727 test: 0.9232\n",
      "15 train: 0.9224909 test: 0.9231\n",
      "16 train: 0.9224909 test: 0.9231\n",
      "17 train: 0.9224909 test: 0.9231\n",
      "18 train: 0.9224909 test: 0.9231\n",
      "19 train: 0.9224909 test: 0.9231\n",
      "20 train: 0.9224909 test: 0.9231\n",
      "21 train: 0.9224909 test: 0.9231\n",
      "22 train: 0.9224909 test: 0.9231\n",
      "23 train: 0.9224909 test: 0.9231\n",
      "24 train: 0.9224909 test: 0.9231\n",
      "25 train: 0.9224909 test: 0.9231\n",
      "26 train: 0.9224909 test: 0.9231\n",
      "27 train: 0.9224909 test: 0.9231\n",
      "28 train: 0.9224909 test: 0.9231\n",
      "29 train: 0.9224909 test: 0.9231\n",
      "30 train: 0.9224909 test: 0.9231\n"
     ]
    }
   ],
   "source": [
    "#5. session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #将图保存下来\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for epoch in range(31):\n",
    "        sess.run(tf.assign(learn,learn*(0.95**epoch))) \n",
    "        for batch in range(n_batch):\n",
    "            #每次向下取出一个batch的数据\n",
    "            train_data,train_label = mnist.train.next_batch(batch_size) #？为什么这里mnist 有 train方法...\n",
    "            summary,_ = sess.run([merge,train_step],feed_dict={data:train_data,label:train_label,keep_prob:1.0})\n",
    "            #传入测试集的数据和标签\n",
    "        writer.add_summary(summary,epoch)\n",
    "        test_acc = sess.run(accuracy,feed_dict={data:mnist.test.images,label:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={data:mnist.train.images,label:mnist.train.labels,keep_prob:1.0})\n",
    "        print(epoch,\"train:\",train_acc,\"test:\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
